[masters]
{% for master_node in (groups.openshift_role_master | intersect(groups['openshift_cluster_' + cluster_name])) %}
{{ hostvars[master_node].private_dns_name }}
{% endfor %}

[etcd]
{% for master_node in (groups.openshift_role_master | intersect(groups['openshift_cluster_' + cluster_name])) %}
{{ hostvars[master_node].private_dns_name }}
{% endfor %}

[nodes]
{% for master_node in (groups.openshift_role_master | intersect(groups['openshift_cluster_' + cluster_name])) %}
{{ hostvars[master_node].private_dns_name }}
{% endfor %}
{% for infra_node in (groups.openshift_role_master | intersect(groups['openshift_cluster_' + cluster_name])) %}
{{ hostvars[infra_node].private_dns_name }} openshift_node_labels="{'role': 'infra'}"
{% endfor %}
{% for app_node in (groups.openshift_role_app | intersect(groups['openshift_cluster_' + cluster_name])) %}
{{ hostvars[app_node].private_dns_name }} openshift_node_labels="{'role': 'app'}"
{% endfor %}

[glusterfs]
{% for infra_node in (groups.openshift_role_master | intersect(groups['openshift_cluster_' + cluster_name])) %}
{{ hostvars[infra_node].private_dns_name }} glusterfs_devices='[ "{{ cns_storage_device }}" ]'
{% endfor %}

# Create an OSEv3 group that contains the masters and nodes groups
[OSEv3:children]
masters
nodes
etcd
glusterfs

[OSEv3:vars]
# Disable checks that are meant to catch issues early. This is an automated install that
# also creates the infrastructure so it is assumed that things are configured correctly.
# This will speed up the execution of the installer.
#openshift_disable_check=memory_availability,disk_availability,docker_storage,docker_storage_driver,docker_image_availability,package_version,package_availability,package_update

###############################################################################
# Common/ Required configuration variables follow                             #
###############################################################################
# SSH user, this user should allow ssh based auth without requiring a
# password. If using ssh key based auth, then the key should be managed by an
# ssh agent.
ansible_user=ec2-user

# If ansible_user is not root, ansible_become must be set to true and the
# user must be configured for passwordless sudo
ansible_become=yes

# Specify the deployment type. Valid values are origin and openshift-enterprise.
#openshift_deployment_type=origin
openshift_deployment_type=openshift-enterprise

# Specify the generic release of OpenShift to install. This is used mainly just during installation, after which we
# rely on the version running on the first master. Works best for containerized installs where we can usually
# use this to lookup the latest exact version of the container images, which is the tag actually used to configure
# the cluster. For RPM installations we just verify the version detected in your configured repos matches this
# release.
openshift_release=v3.9

# default subdomain to use for exposed routes, you should have wildcard dns
# for *.apps.test.example.com that points at your infra nodes which will run
# your router
openshift_master_default_subdomain=apps.{{ cluster_name }}.{{ route53_hosted_zone }}

###############################################################################
# Additional configuration variables follow                                   #
###############################################################################

# Debug level for all OpenShift components (Defaults to 2)
debug_level=2

# Manage openshift example imagestreams and templates during install and upgrade
openshift_install_examples=true

# htpasswd auth
openshift_master_identity_providers=[{'name': 'htpasswd_auth', 'login': 'true', 'challenge': 'true', 'kind': 'HTPasswdPasswordIdentityProvider', 'filename': '/etc/origin/master/htpasswd'}]
# Defining htpasswd users
#openshift_master_htpasswd_users={'user1': '<pre-hashed password>', 'user2': '<pre-hashed password>'}
# or
#openshift_master_htpasswd_file=<path to local pre-generated htpasswd file>

# Enable cockpit
osm_use_cockpit=true
#
# Set cockpit plugins
osm_cockpit_plugins=['cockpit-kubernetes']

# If an external load balancer is used public hostname should resolve to
openshift_master_cluster_public_hostname={{ cluster_name }}.{{ route53_hosted_zone }}
# external load balancer address

# default project node selector
osm_default_node_selector='role=app'

# OpenShift Storage Options
#
openshift_storage_glusterfs_storageclass=true
openshift_storage_glusterfs_storageclass_default=true

# OpenShift Router Options
#
# An OpenShift router will be created during install if there are
# nodes present with labels matching the default router selector,
# "region=infra". Set openshift_node_labels per node as needed in
# order to label nodes.
#
# Example:
# [nodes]
# node.example.com openshift_node_labels="{'region': 'infra'}"
#
# Router selector (optional)
# Router will only be created if nodes matching this label are present.
# Default value: 'region=infra'
openshift_hosted_router_selector='role=infra'

# Openshift Registry Options
#
# An OpenShift registry will be created during install if there are
# nodes present with labels matching the default registry selector,
# "region=infra". Set openshift_node_labels per node as needed in
# order to label nodes.
#
# Example:
# [nodes]
# node.example.com openshift_node_labels="{'region': 'infra'}"
#
# Registry selector (optional)
# Registry will only be created if nodes matching this label are present.
# Default value: 'region=infra'
openshift_hosted_registry_selector='role=infra'

# Registry Storage Options
#
openshift_hosted_registry_storage_kind=glusterfs

# Metrics deployment
# See: https://docs.openshift.com/enterprise/latest/install_config/cluster_metrics.html
#
# By default metrics are not automatically deployed, set this to enable them
openshift_metrics_install_metrics=true
#
# Storage Options
openshift_metrics_cassandra_storage_type=dynamic
#
# Other Metrics Options -- Common items you may wish to reconfigure, for the complete
# list of options please see roles/openshift_metrics/README.md
openshift_metrics_cassandra_nodeselector={'role': 'infra'}
openshift_metrics_hawkular_nodeselector={'role': 'infra'}
openshift_metrics_heapster_nodeselector={'role': 'infra'}

# Logging deployment
#
# Currently logging deployment is disabled by default, enable it by setting this
openshift_logging_install_logging=true
#
# Logging storage config
openshift_logging_es_pvc_dynamic=true
#
# Other Logging Options -- Common items you may wish to reconfigure, for the complete
# list of options please see roles/openshift_logging/README.md
openshift_logging_es_nodeselector={'role': 'infra'}
openshift_logging_curator_nodeselector={'role': 'infra'}
openshift_logging_kibana_nodeselector={'role': 'infra'}

# Prometheus deployment
#
# Currently prometheus deployment is disabled by default, enable it by setting this
openshift_hosted_prometheus_deploy=true
#
# Prometheus storage config
openshift_prometheus_storage_type=pvc
openshift_prometheus_storage_class=glusterfs-storage
openshift_prometheus_alertmanager_storage_type=pvc
openshift_prometheus_alertmanager_storage_class=glusterfs-storage
openshift_prometheus_alertbuffer_storage_type=pvc
openshift_prometheus_alertbuffer_storageinventory_class=glusterfs-storage
#
# Other Prometheus Options
openshift_prometheus_node_selector={'role': 'infra'}
# The default v0.15.2 doesn't exist
openshift_prometheus_node_exporter_image_version=v3.9

# Configure the multi-tenant SDN plugin (default is 'redhat/openshift-ovs-subnet')
os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

# Configure master API and console ports.
openshift_master_api_port=443
openshift_master_console_port=443

# Enable service catalog
openshift_enable_service_catalog=true

# Enable template service broker (requires service catalog to be enabled, above)
template_service_broker_install=true
template_service_broker_selector={'role': 'infra'}

# Firewall configuration
os_firewall_use_firewalld=true
